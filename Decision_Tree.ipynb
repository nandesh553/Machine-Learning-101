{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* entropy in decison tree\n",
    "* information gain, id3, gini, chi square, reduction of variance\n",
    "* pruning\n",
    "* handle overfitting\n",
    "* kaggle decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Decision Tree is a white box type of ML algorithm.\n",
    "* CART - Classification and regression trees.\n",
    "\n",
    "A decision tree is a flowchart-like tree structure where an internal node represents feature(or attribute), the branch represents a decision rule, and each leaf node represents the outcome. The topmost node in a decision tree is known as the root node. It learns to partition on the basis of the attribute value. It partitions the tree in recursively manner call recursive partitioning. This flowchart-like structure helps you in decision making. It's visualization like a flowchart diagram which easily mimics the human level thinking. That is why decision trees are easy to understand and interpret.\n",
    "\n",
    "## Types of decision tree\n",
    "* **Categorical Variable Decision Tree**: Decision Tree which has categorical target variable then it called as categorical variable decision tree.\n",
    "* **Continuous Variable Decision Tree**: Decision Tree which has continuous target variable then it is called as Continuous Variable Decision Tree.\n",
    "\n",
    "## Disadvantages\n",
    "1. **Over fitting**: Over fitting is one of the most practical difficulty for decision tree models. This problem gets solved by setting constraints on model parameters and pruning (discussed in detailed below).\n",
    "2. **Not fit for continuous variables**: While working with continuous numerical variables, decision tree looses information when it categorizes variables in different categories.\n",
    "\n",
    "## Attribute Selection Measures\n",
    "Attribute selection measure is a heuristic for selecting the splitting criterion that partition data into the best possible manner. It is also known as **splitting rules** because it helps us to determine breakpoints for tuples on a given node. ASM provides a rank to each feature(or attribute) by explaining the given dataset. Best score attribute will be selected as a splitting attribute (Source). In the case of a continuous-valued attribute, split points for branches also need to define.\n",
    "\n",
    "The decision of making strategic splits heavily affects a treeâ€™s accuracy. The decision criteria is different for classification and regression trees.\n",
    "\n",
    "The creation of sub-nodes increases the homogeneity of resultant sub-nodes. In other words, we can say that purity of the node increases with respect to the target variable. Decision tree splits the nodes on all available variables and then selects the split which results in most homogeneous sub-nodes.\n",
    "\n",
    "## **What is entropy?**\n",
    "* https://towardsdatascience.com/entropy-how-decision-trees-make-decisions-2946b9c18c8\n",
    "\n",
    "Entropy is less if data is homogeneous\n",
    "\n",
    "Most popular selection measures are:\n",
    "* Information Gain (Entropy)\n",
    "* Gini\n",
    "* Chi-square\n",
    "* Reduction in variance\n",
    "\n",
    "Types\n",
    "* C4.5\n",
    "* ID3 (Entropy)\n",
    "\n",
    "#### Information gain\n",
    "\n",
    "\n",
    "* Search logistic regression vs decision trees\n",
    "* https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/\n",
    "* http://www.saedsayad.com/decision_tree_reg.htm\n",
    "* https://www.datacamp.com/community/tutorials/decision-tree-classification-python\n",
    "* https://towardsdatascience.com/decision-trees-in-machine-learning-641b9c4e8052\n",
    "* https://medium.com/@rishabhjain_22692/decision-trees-it-begins-here-93ff54ef134"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
